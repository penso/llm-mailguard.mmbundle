#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Check a single email for spam using an LLM API.
Reads raw email from stdin, sends to LLM, and returns actions based on result.
"""

import sys
from llm_common import (
    show_alert, show_threat_dialog, load_config,
    get_api_key_from_keychain, call_llm_api,
    output_actions, move_to_junk_action
)

SYSTEM_PROMPT = """You are an email spam classifier. Analyze the following raw email (including all headers and body) and determine if it is spam.

Consider these factors:
- Suspicious sender addresses or domains
- Phishing attempts (requests for personal info, urgent language, suspicious links)
- Unsolicited commercial content
- Scam patterns (lottery wins, inheritance, Nigerian prince, etc.)
- Spoofed headers or suspicious routing
- Malicious attachment indicators
- Social engineering tactics

Respond with EXACTLY one of these two formats:
SPAM: [brief reason]
NOT_SPAM: [brief reason]

Be concise in your reason (one sentence)."""

TITLE = "LLM Spam Classifier"


def parse_response(response):
    """Parse LLM response to determine spam status and reason."""
    response = response.strip()
    upper_response = response.upper()
    
    if upper_response.startswith("SPAM:"):
        return True, response[5:].strip()
    elif upper_response.startswith("NOT_SPAM:"):
        return False, response[9:].strip()
    elif upper_response.startswith("NOT SPAM:"):
        return False, response[9:].strip()
    else:
        # Fallback: check if response contains spam indicators
        if "SPAM" in upper_response and "NOT" not in upper_response:
            return True, response
        return False, response


def main():
    # Load configuration
    config = load_config()
    if not config:
        show_alert("LLM Spam Classifier is not configured.\n\nPlease run Command > LLM Spam Classifier > Configure first.", TITLE)
        output_actions()
        return
    
    endpoint = config.get("endpoint")
    model = config.get("model")
    
    if not endpoint or not model:
        show_alert("LLM Spam Classifier configuration is incomplete.\n\nPlease run Configure again.", TITLE)
        output_actions()
        return
    
    # Get API key from Keychain
    api_key = get_api_key_from_keychain()
    
    # Read raw email from stdin
    raw_email = sys.stdin.read()
    
    if not raw_email.strip():
        show_alert("No email content received.", TITLE)
        output_actions()
        return
    
    # Call LLM API
    try:
        response = call_llm_api(endpoint, model, api_key, SYSTEM_PROMPT, raw_email)
    except Exception as e:
        show_alert(f"Error calling LLM API:\n\n{str(e)}", TITLE)
        output_actions()
        return
    
    if not response:
        show_alert("No response received from LLM API.", TITLE)
        output_actions()
        return
    
    # Parse response
    is_spam, reason = parse_response(response)
    
    if is_spam:
        if show_threat_dialog("SPAM DETECTED", reason, TITLE):
            output_actions([move_to_junk_action()])
        else:
            output_actions()
    else:
        show_alert(f"This email does not appear to be spam.\n\nReason: {reason}", TITLE)
        output_actions()


if __name__ == "__main__":
    main()
